Kubernetes has become a core technology in today’s cloud and DevOps ecosystem. Before jumping into setting up a Kubernetes cluster, it’s important to understand a few key concepts that make it all work.

A **node** in Kubernetes is simply a machine — physical or virtual — where Kubernetes is installed. Each node acts as a **worker machine**, and this is where your **containers** actually run. In older versions of Kubernetes, nodes were called *minions*, so you might still come across that term.

Now, imagine the node running your application suddenly fails. Naturally, your application would go down too. To avoid this, Kubernetes uses a **cluster**, which is a group of nodes working together. This setup provides **high availability** (your app keeps running even if one node fails) and **load sharing** (traffic and workloads are distributed evenly across nodes).

So, who manages all these nodes? That’s the job of the **master node**. The master node oversees the entire cluster, keeps track of all the nodes, and handles scheduling, scaling, and recovery when something goes wrong. Essentially, it’s the brain of your Kubernetes setup.

When you install Kubernetes, several key components are deployed:

* The **API Server** is the front end of Kubernetes. All commands and management tools (like `kubectl`) communicate through it.
* **etcd** is a distributed key-value store that keeps all cluster data, such as node information and configurations. It ensures consistency across the cluster.
* The **Scheduler** is responsible for assigning new containers (or pods) to available nodes based on their resources.
* **Controllers** act as the decision-makers — they detect failures and automatically create or restart containers as needed.
* The **Container Runtime** (such as Docker, containerd, or CRI-O) is what actually runs your containers.
* The **Kubelet** is an agent that runs on each node and makes sure containers are running as expected.

In short, Kubernetes clusters are made up of two main parts: **Master Nodes** and **Worker Nodes**.
The **Master Node** runs the control components — API Server, Controller Manager, Scheduler, and etcd — while the **Worker Nodes** run the actual applications via the Kubelet and container runtime. The workers report their status to the master, and the master decides what to run where.

To interact with your cluster, Kubernetes provides a command-line tool called **kubectl** (pronounced “cube control”). You’ll use it to deploy and manage applications, check cluster health, and view node details. Some basic commands include:

* `kubectl run` → Deploys an application on the cluster
* `kubectl cluster-info` → Displays information about the cluster
* `kubectl get nodes` → Lists all the nodes in the cluster

As you continue learning Kubernetes, you’ll use more advanced `kubectl` commands, but these few are great starting points.

In summary, Kubernetes works by combining multiple machines (nodes) into a single, powerful system that can automatically deploy, scale, and manage containerized applications. Understanding how the master and worker nodes, along with their core components, interact is the foundation for building and maintaining a stable Kubernetes environment.
